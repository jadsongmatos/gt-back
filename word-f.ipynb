{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a2546d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "ds_stream = load_dataset(\"HuggingFaceFW/fineweb-2\", \"por_Latn\", split=\"train\", streaming=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25ea6eb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IterableDataset({\n",
       "    features: ['text', 'id', 'dump', 'url', 'date', 'file_path', 'language', 'language_score', 'language_script', 'minhash_cluster_size', 'top_langs'],\n",
       "    num_shards: 1\n",
       "})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "82369b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"pt_core_news_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "63bfda5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-15 16:02:10,599 INFO sqlalchemy.engine.Engine select pg_catalog.version()\n",
      "2025-05-15 16:02:10,600 INFO sqlalchemy.engine.Engine [raw sql] {}\n",
      "2025-05-15 16:02:10,601 INFO sqlalchemy.engine.Engine select current_schema()\n",
      "2025-05-15 16:02:10,601 INFO sqlalchemy.engine.Engine [raw sql] {}\n",
      "2025-05-15 16:02:10,602 INFO sqlalchemy.engine.Engine show standard_conforming_strings\n",
      "2025-05-15 16:02:10,602 INFO sqlalchemy.engine.Engine [raw sql] {}\n",
      "2025-05-15 16:02:10,602 INFO sqlalchemy.engine.Engine BEGIN (implicit)\n",
      "2025-05-15 16:02:10,604 INFO sqlalchemy.engine.Engine SELECT pg_catalog.pg_class.relname \n",
      "FROM pg_catalog.pg_class JOIN pg_catalog.pg_namespace ON pg_catalog.pg_namespace.oid = pg_catalog.pg_class.relnamespace \n",
      "WHERE pg_catalog.pg_class.relname = %(table_name)s AND pg_catalog.pg_class.relkind = ANY (ARRAY[%(param_1)s, %(param_2)s, %(param_3)s, %(param_4)s, %(param_5)s]) AND pg_catalog.pg_table_is_visible(pg_catalog.pg_class.oid) AND pg_catalog.pg_namespace.nspname != %(nspname_1)s\n",
      "2025-05-15 16:02:10,605 INFO sqlalchemy.engine.Engine [generated in 0.00030s] {'table_name': 'contadores', 'param_1': 'r', 'param_2': 'p', 'param_3': 'f', 'param_4': 'v', 'param_5': 'm', 'nspname_1': 'pg_catalog'}\n",
      "2025-05-15 16:02:10,606 INFO sqlalchemy.engine.Engine COMMIT\n",
      "Tabela criada (sync).\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import create_engine, MetaData, Table, Column, Integer, Text, Index\n",
    "\n",
    "# Engine síncrono para criação da tabela\n",
    "sync_engine = create_engine(\"postgresql+psycopg2://jadson:jadson@localhost/jadson\", echo=True)\n",
    "metadata = MetaData()\n",
    "\n",
    "contadores = Table(\n",
    "    \"contadores\",\n",
    "    metadata,\n",
    "    Column(\"token\", Text, nullable=False, primary_key=True),\n",
    "    Column(\"quantidade\", Integer, nullable=False),\n",
    ")\n",
    "\n",
    "contadores_token_hash_idx = Index(\n",
    "    \"contadores_token_hash_idx\",\n",
    "    contadores.c.token,\n",
    "    postgresql_using=\"hash\"\n",
    ")\n",
    "\n",
    "# Criar tabela e índice\n",
    "metadata.create_all(bind=sync_engine)\n",
    "print(\"Tabela criada (sync).\")\n",
    "sync_engine.dispose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4941f25f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy.ext.asyncio import create_async_engine, AsyncSession\n",
    "from sqlalchemy.dialects.postgresql import insert\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "# Criar engine async\n",
    "async_engine = create_async_engine(\"postgresql+asyncpg://jadson:jadson@localhost/jadson\", echo=False)\n",
    "\n",
    "# Async session factory\n",
    "AsyncSessionLocal = sessionmaker(\n",
    "    async_engine, expire_on_commit=False, class_=AsyncSession\n",
    ")\n",
    "\n",
    "executor = ThreadPoolExecutor(max_workers=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "29672212",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nlp_process(text):\n",
    "    # Processa texto e retorna tokens (ids)\n",
    "    doc = nlp(text)\n",
    "    return [token.text for token in doc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ef553e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "from collections import Counter\n",
    "\n",
    "MAX_PARAMS = 30000  # limite seguro, abaixo de 32767\n",
    "\n",
    "def chunks(data, max_params=MAX_PARAMS):\n",
    "    max_batch_size = max_params // 2  # 2 params por registro: token e quantidade\n",
    "    for i in range(0, len(data), max_batch_size):\n",
    "        yield data[i:i + max_batch_size]\n",
    "\n",
    "async def processar_batch(textos):\n",
    "    loop = asyncio.get_event_loop()\n",
    "\n",
    "    # Processa os textos em executor paralelo\n",
    "    tasks = [loop.run_in_executor(executor, nlp_process, texto) for texto in textos]\n",
    "    resultados = await asyncio.gather(*tasks)\n",
    "\n",
    "    counter = Counter()\n",
    "    for tokens in resultados:\n",
    "        counter.update(tokens)\n",
    "\n",
    "    # Prepara dados convertendo token para decimal.Decimal\n",
    "    data = [\n",
    "        {\n",
    "            \"token\": token,\n",
    "            \"quantidade\": count\n",
    "        }\n",
    "        for token, count in counter.items()\n",
    "    ]\n",
    "\n",
    "    async with AsyncSessionLocal() as session:\n",
    "        async with session.begin():\n",
    "            for data_chunk in chunks(data):\n",
    "                stmt = insert(contadores).values(data_chunk)\n",
    "                stmt = stmt.on_conflict_do_update(\n",
    "                    index_elements=[contadores.c.token],\n",
    "                    set_={\"quantidade\": contadores.c.quantidade + stmt.excluded.quantidade},\n",
    "                )\n",
    "                await session.execute(stmt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c9d93491",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches processados: 33 batch [18:15, 33.21s/ batch]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "async def processar_tokens_batch(batch_size=1000):\n",
    "    batch_texts = []\n",
    "    with tqdm(desc=\"Batches processados\", unit=\" batch\") as pbar:\n",
    "        for exemplo in ds_stream:\n",
    "            texto = exemplo.get(\"text\")\n",
    "            if texto:\n",
    "                batch_texts.append(texto)\n",
    "            if len(batch_texts) >= batch_size:\n",
    "                await processar_batch(batch_texts)\n",
    "                batch_texts = []\n",
    "                pbar.update(1)\n",
    "        if batch_texts:\n",
    "            await processar_batch(batch_texts)\n",
    "            pbar.update(1)\n",
    "\n",
    "asyncio.run(processar_tokens_batch())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f172b08b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import select\n",
    "\n",
    "async def teste_contagem_simples():\n",
    "    frases_teste = [\n",
    "        \"Olá, tudo bem?\",\n",
    "        \"Estou testando a contagem de tokens.\",\n",
    "        \"Olá, tudo bem?\",  # repete para testar incremento\n",
    "    ]\n",
    "    \n",
    "    # Processa e insere no banco\n",
    "    await processar_batch(frases_teste)\n",
    "    \n",
    "    # Ler e mostrar os dados do banco para conferir\n",
    "    async with AsyncSessionLocal() as session:\n",
    "        result = await session.execute(select(contadores).order_by(contadores.c.quantidade.desc()))\n",
    "        rows = result.fetchall()\n",
    "        print(\"Conteúdo da tabela 'contadores':\")\n",
    "        for row in rows:\n",
    "            print(f\"Token ID: {row.token}, Quantidade: {row.quantidade}, Texto: {nlp.vocab.strings[row.token]}\")\n",
    "\n",
    "# Executar teste\n",
    "asyncio.run(teste_contagem_simples())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spacy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
